# The Learning Mechanism of LLMs

Archived: No
Favorite: No
Datum: July 20, 2025

# Summary

The speaker discusses the evolution of large language models (LLMs) and their learning processes. They highlight improvements in training methods, the development of tools for enhanced user interaction, and the emergence of memory and thinking modes outside of the models themselves. The speaker compares these advancements to the human brain and anticipates future developments in artificial intelligence, noting the speed and capacity of AI to process vast amounts of data compared to human cognition.

# Translated Transcript (English)

Does an LLM learn? Yes, of course it learns. But does it become smarter as a result? So far, or the early approaches of the LLMs were like that, namely the first version, JGBT.

One asks something, and one immediately gets the answer at the back, which is what the model has found through the Attention Transformer, as coherent sentences and which words fit together and what the best matches are for the tokens from the prediction. JGBT is not a model in itself, but a tool to interact with the model. And over the last two years, these tools have been continuously developed. The learning methods for the models have naturally improved, as researchers have realized that reinforcement learning can extract even more from the model, fine-tuning and specializing it further.

At the same time, the tooling around it has also improved. For example, how data is prepared for the model. Metaprompts, system prompts, and what is now new is the ability to create profiles where you can store your own prompts and data so that the model responds better to you. The models have gained memory, which is not in the model itself, but rather a tool, a functionality that exists alongside it.

Deep Thinking or the Thinking Mode are all things that are not inherently part of the model, but are built around it to enable much more. For example, in the Thinking Mode, you input data, the model produces an output, but it is not directly returned to the user; instead, it is fed back into the model, likely with an additional prompt or command set, to reassess the output under different circumstances. This loop can be repeated as many times as desired to improve the result, and it can also be parallelized and run through different phases. And as a result, the models, or the AI, become significantly stronger because they can think in a way, which is essentially nothing more than running the data through the models in various iterations.

And this can be scaled indefinitely. How far this can be scaled and whether it makes sense to scale too much is still up for debate, but the technology will continue to grow. If I compare this spontaneously with the brain, we also have different areas in the brain; it is not just a gray mass, but we have different brain regions, we have different parts of the brain that are also structured differently. And I can imagine that if we want to achieve a general artificial intelligence that is truly intelligent, it should be built from various components.

And that definitely makes sense. I am very curious about what ideas will come our way in the near future. The advantage that AI has in our technological universe is that it can access more data in no time, and now with the MCP servers, it can draw from even more sources, and the data processing is significantly faster than what we can do with our brains. Of course, we have our memories and can access them.

However, sometimes we also have to dig and work in the subconscious, which needs to be active. And here, of course, AI has a clear advantage in that it can access information ad hoc and directly. So, let's be curious about what will happen next.

# Transcript (German)

Lernt ein LLM dazu? Ja, natürlich lernt es dazu. Aber wird es dadurch auch intelligenter? Bisher, oder die frühen Ansätze des LLMs waren ja das, also die erste Version, JGBT.

Man fragt etwas, man bekommt sofort die Antwort hinten raus, was das Modell durch den Attention Transformer gefunden hat, als zusammenhängende Sätze und welche Worte zusammenpassen und was von der Vorhersage die Best Matches sind für die Tokens. Das ist das, was man rausbekommen hat. JGBT ist ja kein Modell an sich, sondern es ist ein Tool, um mit dem Modell zu interagieren. Und über die letzten zwei Jahre haben sich diese Tools immer weiter ausgebaut.

Die Lernmethoden für die Modelle haben sich natürlich verbessert, wo die Forscher gemerkt haben, durch Reinforcement Learning kriegt man noch mehr aus dem Modell raus, man kriegt es noch besser in Richtung getrimmt, spezialisiert. Was aber natürlich gleichzeitig gemacht wurde, ist das Tooling drumherum verbessert. Also, wie werden Daten aufbereitet, die an das Modell gehen? Metaprompts, Systemprompts, was jetzt neuerdings ist, dass man Profile anlegen kann, wo man seinen eigenen Prompt, seine eigenen Daten hinterlegen kann, damit das Modell besser auf dich reagiert.

Die Modelle haben Gedächtnis bekommen, das ist nicht im Modell selber, sondern das ist ein Tool, eine Funktionalität, die an der Seite liegt. Auch das Deep Thinking oder das Thinking Modus, das sind alles Dinge, die natürlich nicht im Modell drin sind, sondern drumherum gebaut werden, um vieles mehr zu ermöglichen. Also zum Beispiel wartet man beim Thinking Modus, man gibt den Input rein, das Modell gibt ein Output raus, aber er wird nicht direkt an den User zurückgegeben, sondern er wird einfach wieder ins Modell gegeben, wahrscheinlich mit noch einem extra Prompt oder einem extra Befehlssatz, um das, was als Ausgabe rauskommt, nochmal neu zu bewerten, unter anderen Umständen. Und diesen Loop kann man natürlich beliebig oft wiederholen, um das Ergebnis zu verbessern und man kann auch es parallelisieren und in verschiedenen Phasen durchlaufen.

Und dadurch werden die Modelle natürlich, oder die KI wird dadurch natürlich wesentlich stärker, weil sie so gesehen denken kann, was aber ja eigentlich nichts anderes ist, als die Daten in verschiedenen, in mehreren Iterationen durch die Modelle laufen zu lassen. Und das kann man natürlich beliebig skalieren. Wie weit sich das skalieren lässt und ob es Sinn macht, zu oft zu skalieren, sei erstmal hingestellt, aber da wird die Technologie weiter wachsen. Wenn ich das jetzt so einfach spontan mit dem Gehirn vergleiche, wir haben ja im Gehirn auch verschiedene Areale, es ist ja nicht einfach nur eine graue Masse, sondern wir haben verschiedene Gehirnregionen, wir haben verschiedene Teile des Gehirns, die auch anders aufgebaut sind.

Und ich kann mir vorstellen, dass wenn man zu einer allgemeinen künstlichen Intelligenz kommen möchte, dass das auch wirklich intelligent ist, dass es da aus den verschiedenen Komponenten gebaut werden soll. Und das macht natürlich auch definitiv Sinn. Ich bin sehr gespannt, was da in nächster Zukunft noch an Ideen auf uns zukommt. Der Vorteil, den die KI natürlich hat in unserem Technikuniversum, ist, sie kann in keiner Zeit noch auf mehr Daten zugreifen und jetzt durch die MCP-Server noch mehr Quellen ranziehen und die Datenverarbeitung ist da wesentlich schneller als das, was wir mit unserem Gehirn machen.

Wir haben natürlich unsere Erinnerungen und können darauf zugreifen. Teilweise müssen wir aber auch graben und im Unterbewusstsein, das muss laufen. Und da hat natürlich die KI einen deutlichen Vorteil, dass sie ad hoc und direkt auf Informationen zugreifen kann. Also, seien wir gespannt, was da noch passieren wird.

# Additional Info

## Main Points

- LLMs learn and improve through advancements in training methods, including reinforcement learning.
- New tools have been developed to enhance the interaction between users and models, including metaprompts and personalized profiles.
- The concept of memory in AI is implemented through functionalities outside the model itself.
- Thinking modes allow iterative processing of data to refine outputs, akin to human cognitive processes.
- AI has significant advantages in data access and processing speed compared to human memory retrieval.

## Potential Action Items

- [ ]  Explore more about reinforcement learning for LLMs (2025-07-21).
- [ ]  Investigate the implications of personalized user profiles on AI interaction (2025-07-21).
- [ ]  Keep updated on future developments in AI technology and potential advancements (2025-07-21).

## Follow-Up Questions

- What specific advancements in reinforcement learning have been most impactful?
- How can personalized profiles be effectively integrated into existing AI models?
- What ethical considerations arise from the use of advanced memory functions in AI?

## Arguments and Areas for Improvement

<aside>
⚠️ These are potential arguments and rebuttals that other people may bring up in response to the transcript. Like every other part of this summary document, factual accuracy is not guaranteed.

</aside>

- There may be concerns about the over-reliance on AI's processing speed, possibly undermining human critical thinking.
- The implementation of memory and thinking modes could lead to complexities in data processing that obscure transparency.
- AI's potential to improve through iteration might not guarantee genuine intelligence or understanding.

## Related Topics

- cognitive science comparisons
- future of general artificial intelligence
- memory systems in artificial intelligence
- reinforcement learning in ai
- user interaction with ai tools